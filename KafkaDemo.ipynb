{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59b2d799",
   "metadata": {},
   "source": [
    "# Kafka Demo\n",
    "\n",
    "### Connect to Kafka Broker Server\n",
    "```\n",
    "ssh -o ServerAliveInterval=60 -L 9092:localhost:9092 tunnel@128.2.204.215 -NTf\n",
    "```\n",
    "password for tunnel@128.2.204.215: mlip-tunnel\n",
    "\n",
    "\n",
    "To kill connection at port:\n",
    "```\n",
    "lsof -ti:9092 | xargs kill -9\n",
    "```\n",
    "\n",
    "### Setup\n",
    "```\n",
    "python -m pip install kafka-python\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "560fd2bb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T13:03:03.131772Z",
     "start_time": "2024-09-03T13:03:03.127113Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "from json import dumps, loads\n",
    "from time import sleep\n",
    "from random import randint\n",
    "from kafka import KafkaConsumer, KafkaProducer\n",
    "\n",
    "# Update this for your own recitation section :)\n",
    "topic = 'recitation-x' # x could be b, c, d, e, f"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb9dd6f",
   "metadata": {},
   "source": [
    "### Producer Mode -> Writes Data to Broker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa4679a1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T13:02:46.568192Z",
     "start_time": "2024-09-03T13:02:46.462832Z"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ellipsis' object has no attribute 'strip'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-2-2ae585732407>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0;31m# [TODO]: Replace '...' with the address of your Kafka bootstrap server\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 5\u001B[0;31m producer = KafkaProducer(bootstrap_servers=[...],\n\u001B[0m\u001B[1;32m      6\u001B[0m                         \u001B[0mvalue_serializer\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mlambda\u001B[0m \u001B[0mx\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mdumps\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mencode\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'utf-8'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      7\u001B[0m                         )\n",
      "\u001B[0;32m~/miniconda3/lib/python3.9/site-packages/kafka/producer/kafka.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, **configs)\u001B[0m\n\u001B[1;32m    379\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_metrics\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mMetrics\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmetric_config\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mreporters\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    380\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 381\u001B[0;31m         client = KafkaClient(metrics=self._metrics, metric_group_prefix='producer',\n\u001B[0m\u001B[1;32m    382\u001B[0m                              \u001B[0mwakeup_timeout_ms\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mconfig\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'max_block_ms'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    383\u001B[0m                              **self.config)\n",
      "\u001B[0;32m~/miniconda3/lib/python3.9/site-packages/kafka/client_async.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, **configs)\u001B[0m\n\u001B[1;32m    208\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_selector\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mconfig\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'selector'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    209\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 210\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcluster\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mClusterMetadata\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m**\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mconfig\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    211\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_topics\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mset\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m  \u001B[0;31m# empty set will fetch all topic metadata\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    212\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_metadata_refresh_in_progress\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mFalse\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/lib/python3.9/site-packages/kafka/cluster.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, **configs)\u001B[0m\n\u001B[1;32m     65\u001B[0m                 \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mconfig\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mkey\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mconfigs\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mkey\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     66\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 67\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_bootstrap_brokers\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_generate_bootstrap_brokers\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     68\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_coordinator_brokers\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m{\u001B[0m\u001B[0;34m}\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     69\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/lib/python3.9/site-packages/kafka/cluster.py\u001B[0m in \u001B[0;36m_generate_bootstrap_brokers\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     70\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_generate_bootstrap_brokers\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     71\u001B[0m         \u001B[0;31m# collect_hosts does not perform DNS, so we should be fine to re-use\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 72\u001B[0;31m         \u001B[0mbootstrap_hosts\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcollect_hosts\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mconfig\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'bootstrap_servers'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     73\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     74\u001B[0m         \u001B[0mbrokers\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m{\u001B[0m\u001B[0;34m}\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/lib/python3.9/site-packages/kafka/conn.py\u001B[0m in \u001B[0;36mcollect_hosts\u001B[0;34m(hosts, randomize)\u001B[0m\n\u001B[1;32m   1495\u001B[0m     \u001B[0;32mfor\u001B[0m \u001B[0mhost_port\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mhosts\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1496\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1497\u001B[0;31m         \u001B[0mhost\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mport\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mafi\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mget_ip_port_afi\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mhost_port\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1498\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1499\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mport\u001B[0m \u001B[0;34m<\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/lib/python3.9/site-packages/kafka/conn.py\u001B[0m in \u001B[0;36mget_ip_port_afi\u001B[0;34m(host_and_port_str)\u001B[0m\n\u001B[1;32m   1448\u001B[0m         \u001B[0;34m:\u001B[0m\u001B[0;32mreturn\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mtuple\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mhost\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mport\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mafi\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mafi\u001B[0m \u001B[0mwill\u001B[0m \u001B[0mbe\u001B[0m \u001B[0msocket\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mAF_INET\u001B[0m \u001B[0;32mor\u001B[0m \u001B[0msocket\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mAF_INET6\u001B[0m \u001B[0;32mor\u001B[0m \u001B[0msocket\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mAF_UNSPEC\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1449\u001B[0m     \"\"\"\n\u001B[0;32m-> 1450\u001B[0;31m     \u001B[0mhost_and_port_str\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mhost_and_port_str\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstrip\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1451\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mhost_and_port_str\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstartswith\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'['\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1452\u001B[0m         \u001B[0maf\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0msocket\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mAF_INET6\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'ellipsis' object has no attribute 'strip'"
     ]
    }
   ],
   "source": [
    "# Create a producer to write data to kafka\n",
    "# Ref: https://kafka-python.readthedocs.io/en/master/apidoc/KafkaProducer.html\n",
    "\n",
    "# [TODO]: Replace '...' with the address of your Kafka bootstrap server\n",
    "producer = KafkaProducer(bootstrap_servers=[...],\n",
    "                        value_serializer=lambda x: dumps(x).encode('utf-8'))\n",
    "\n",
    "# [TODO]: Add cities of your choice\n",
    "cities = []\n",
    "\n",
    "# Write data via the producer\n",
    "print(\"Writing to Kafka Broker\")\n",
    "for i in range(10):\n",
    "    data = f'{datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")},{cities[randint(0,len(cities)-1)]},{randint(18, 32)}ºC'\n",
    "    print(f\"Writing: {data}\")\n",
    "    producer.send(topic=topic, value=data)\n",
    "    sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a45bbace",
   "metadata": {},
   "source": [
    "### Consumer Mode -> Reads Data from Broker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5e2f59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a consumer to read data from kafka\n",
    "# Ref: https://kafka-python.readthedocs.io/en/master/apidoc/KafkaConsumer.html\n",
    "\n",
    "# [TODO]: Complete the missing ... parameters/arguments using the Kafka documentation\n",
    "consumer = KafkaConsumer(\n",
    "    ...,\n",
    "    bootstrap_servers=[...],\n",
    "    auto_offset_reset=..., #Experiment with different values\n",
    "    # Commit that an offset has been read\n",
    "    enable_auto_commit=True,\n",
    "    # How often to tell Kafka, an offset has been read\n",
    "    auto_commit_interval_ms=1000\n",
    ")\n",
    "\n",
    "print('Reading Kafka Broker')\n",
    "for message in consumer:\n",
    "    message = message.value.decode()\n",
    "    # Default message.value type is bytes!\n",
    "    print(loads(message))\n",
    "    os.system(f\"echo {message} >> kafka_log.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38927152",
   "metadata": {},
   "source": [
    "# Use kcat!\n",
    "It's a CLI (Command Line Interface). Previously known as kafkacat\n",
    "\n",
    "\n",
    "Ref: https://docs.confluent.io/platform/current/app-development/kafkacat-usage.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19b63da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#kcat command: connect to local Kafka broker, specify a topic, and consume messages from the earliest offset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
